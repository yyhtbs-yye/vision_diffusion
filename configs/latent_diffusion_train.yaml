model:
  type: LatentDiffusionModel
  
  vae_pretrained: "stabilityai/sd-vae-ft-mse"  # Example: A common pretrained VAE from Stable Diffusion
  
  unet_config:
    sample_size: [32, 32]  # Size of the latent space
    in_channels: 4         # Latent channels from VAE
    out_channels: 4        # Same as input for prediction
    down_block_types: ['DownBlock2D', 'DownBlock2D', 'DownBlock2D', 'AttnDownBlock2D']
    up_block_types: ['AttnUpBlock2D', 'UpBlock2D', 'UpBlock2D', 'UpBlock2D']
    block_out_channels: [128, 256, 512, 512]
    layers_per_block: 2
    attention_head_dim: 8
    norm_num_groups: 32
    norm_eps: 0.00001
  
  train_scheduler_config:
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: "linear"
    steps_offset: 1
    clip_sample: false
    set_alpha_to_one: false
    prediction_type: "epsilon"
    num_train_timesteps: 1000
  
  test_scheduler_config:
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: "linear"
    steps_offset: 1
    clip_sample: false
    set_alpha_to_one: false
    prediction_type: "epsilon"
    num_train_timesteps: 1000
  
  eta: 0.0                    # Parameter controlling noise level in sampling
  num_inference_steps: 50     # Default sampling steps for inference

validation:
  num_vis_samples: 4          # Number of samples to visualize during validation

# Optimizer configuration
optimizer:
  learning_rate: 0.00001
  betas: [0.9, 0.999]
  weight_decay: 0.0
  use_ema: true
  ema_decay: 0.999
  ema_start: 1000
  noise_offset_weight: 0.0    # Parameter for noise offset (disabled in your code)

# Data configuration
data:
  # Training dataloader configuration
  train_dataloader:
    dataset:
      data_root: datasets/ffhq/ffhq_imgs/ffhq_256
      type: SingleImageDataset
      data_prefix:
        gt: ''
      pipeline:
        - type: LoadImageFromFile
          key: gt
        - type: Crop
          keys: [gt]
          crop_size: [256, 256]
          is_pad_zeros: true
          random_crop: false
        - type: Normalize
          keys: [gt]
          mean: [0.5, 0.5, 0.5]
          std: [0.5, 0.5, 0.5]
        - type: PackInputs
    batch_size: 16
    num_workers: 4
    persistent_workers: true
    sampler:
      type: DefaultSampler
      shuffle: true

  # Validation dataloader configuration
  val_dataloader:
    dataset:
      data_root: datasets/img_align_celeba/random_subset
      type: SingleImageDataset
      data_prefix:
        gt: ''
      pipeline:
        - type: LoadImageFromFile
          key: gt
        - type: Crop
          keys: [gt]
          crop_size: [256, 256]
          is_pad_zeros: true
          random_crop: false
        - type: Normalize
          keys: [gt]
          mean: [0.5, 0.5, 0.5]
          std: [0.5, 0.5, 0.5]
        - type: PackInputs
    batch_size: 16
    num_workers: 4
    persistent_workers: true
    sampler:
      type: DefaultSampler
      shuffle: false

# Training configuration
train:
  max_steps: 300000
  val_check_interval: 100

# Logging configuration
logging:
  log_dir: work_dirs/latent_diffusion
  experiment_name: latent_diffusion_model
  log_every_n_steps: 100

# Checkpoint configuration
checkpoint:
  save_best_metric: 'val/latent_mse'  # Metric to monitor for saving best models
  save_best_mode: 'min'               # 'min' for loss metrics
  save_top_k: 3                       # Number of best checkpoints to keep
  save_last: true                     # Whether to save the last checkpoint

# Hooks configuration
default_hooks:
  checkpoint:
    save_best: latent_mse
    rule: less
  timer:
    type: IterTimerHook
  logger:
    type: LoggerHook
    interval: 100
  param_scheduler:
    type: ParamSchedulerHook
  sampler_seed:
    type: DistSamplerSeedHook

# Evaluation configuration
val_evaluator:
  metrics: 
    - type: MSE
    - type: PSNR
    - type: SSIM

# Visualization configuration
visualization:
  vis_backends:
    - type: LocalVisBackend
  visualizer:
    type: ConcatImageVisualizer
    vis_backends: ${visualization.vis_backends}
    fn_key: gt_path
    img_keys: [gt_img, pred_img]
    bgr2rgb: true
  custom_hooks:
    - type: BasicVisualizationHook
      interval: 1